{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyR/WWDJmcbBQN9BDxlM00",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihun5/data-preprocessing_/blob/main/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EA%B8%B0%EB%B0%98%EC%8B%9C%EB%8C%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 분석 인재에게 필요한 스킬\n",
        "1. 비즈니스 능력 : 과제의 배경을 이해한 다음 비즈니스의 과제를 이해하고 해결하는 능력\n",
        "2. 데이터 사이언스 : 정보처리, 인공지능, 통계학 등과 같은 정보과학계의 지혜를 이해하고 사용하는 능력\n",
        "3. 데이터 엔지니어링 능력 : 데이터 사이언스를 의미가 있는 형태로 사용할 수 있도록 만들어, 설치, 운용할 수 있는 능력\n",
        "\n",
        "순서\n",
        "- 문제파악 - 데이터의 이해 - 데이터 준비 - 모델 작성 - 평가 - 베포 공유\n",
        "\n",
        "데이터의 이해\n",
        "- 언제, 어디에서, 왜? 데이터를 수집했는가?\n",
        "- 데이터의 간격은?\n",
        "- 데이터가 의미하는 것은?\n",
        "- 데이터를 취득할 때 고려해야하는 사항, 빠진 부분이 있는가?\n",
        "- 결측치와 이상치의 여부\n",
        "- 각 컬럼 간 관련성이 있는가?\n",
        "\n",
        "데이터 준비\n",
        "- 정형 데이터 : 표 형식으로 표현할 수 있는 즉, 고객 데이터나 구매 이력같은 형태\n",
        "- 비정형 데이터 : 이미지, 문장, 음성 같은 데이터\n",
        "\n",
        "모델 작성\n",
        "- 비지도학습, 지도학습, 강화학습\n",
        "- 지도학습 : 분류, 회귀\n",
        "  - 학습단계(목적변수)를 포함한 데이터 세트를 입력데이터로 사용\n",
        "  - 목적변수를 제외한 설명변수로부터 얻어지는 출력 결과에 주목한다.\n",
        "  - 가장 중요한 요인들을 선택하여 학습하고, 파라미터를 조정하여 모델링\n",
        "  - K-최근접 이웃, 의사결정 트리, 랜덤 포레스트, 선형회귀, 로지스틱 회귀, 나이브 베이즈 분류, 서포터 벡터 머신, 신경망 등이 있다.\n",
        "- 비지도 학습 : 그룹화, 차원압축\n",
        "  - 설명변수만 있는 데이터세트\n",
        "  - 마지막에 레이블을 붙여서 의미있는 정보로 만든다.\n",
        "  - 주성분 분석, 대응분석, 연관성 분석, 계층/비계층 클러스터링, 네트워크 분석 등이 있다.\n",
        "- 강화학습 : 기계가 스스로 학습해 나가면서 처리를 최적화하고 목표를 달성\n",
        "\n",
        "모델 검증\n",
        "- 여러 번의 학습을 거쳐서 성능을 검증하고 성능을 높인 후에 사용한다.(교차검증법)\n",
        "- 교차 검증법에서는 우선 데이터를 랜덤하게 분할하고 훈련데이터와 테스트 데이터를 작성한다.(ex) 데이터를 10개로 분할해 9개를 훈련, 1개를 검증데이터로 사용)\n",
        "- 모델의 성능 계산에는 오차행렬을 사용한다.\n",
        "  - TP(True인데 True로 출력한 건수의미) / FN(True인데 False로 출력한 건수) / FP(False인데 True로 출력한 건수) / TN(False인데 False로 출력한 건수)\n",
        "  - 위 결과를 사용해서 계산된 지표가 재현율과 적합률이다.\n",
        "- 과적합 : 너무 데이터 맞춰서 모델링 되었거나 충분히 학습하지 못한 상태 -> 변수를 추가하거나 축소하거나 다른 모델링을 선택하거나, 교차검증, 파라미터 수정 등의 과정을 거쳐야 한다.\n",
        "- 파라미터 조정 : 그리드 서치를 통해 최적의 파라미터를 선택하는 과정을 보통 선택한다.\n",
        "- 변수선택 : 특징이 없는 변수를 포함시켜 모델을 작성하면 속도의 성능의 저하를 불러온다,\n",
        "  - 전진선택법 : 변수를 추가해가면서 모델을 작성하여 성능을 측정\n",
        "  - 후진제거법 : 변수를 제거해가면서 모댈을 작성하여 성능을 측정\n",
        "\n",
        "평가 : 예측 성능이 높은 모델과 근거를 설명하기 쉬운 모델 중 어느 쪽에 적합한지는 트레이드오프(상충관계)의 관계이다. ex) 납득할만한 ROI까지 신규 고객이 증가하는 것\n",
        "\n",
        "배포/공유 : 업무 프로세스에 베포, 공유, 통합, 유지, 관리\n",
        "\n",
        "-> 가장 중요한 단계는 비즈니스의 이해, 비즈니스의 목적을 이해하고, 분석 목표와 성공의 판정 기준을 올바르게 설정할 수 없으면, 남은 단계의 작업이 의미를 잃어버리게 된다.\n"
      ],
      "metadata": {
        "id": "wjS3x7fFHHP2"
      }
    }
  ]
}